import urllib.request
import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

# 目标网址
url = "https://www.xiaohongshu.com/user/profile/55d495cac2bdeb7f00d211d6"

# 请求头，模拟浏览器行为
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36"
}

# 发送HTTP请求并获取网页源代码
response = requests.get(url, headers=headers)
html = response.text

# 解析HTML页面
soup = BeautifulSoup(html, "html.parser")

# 获取图片链接
image_links = []
# 查找所有<section>标签
sections = soup.find_all("section")
for section in sections:
    # 查找<section>内的所有<img>标签
    img_tags = section.find_all("img")
    for img_tag in img_tags:
        # 添加图片链接到列表中
        img_src = img_tag.get("src")
        if img_src and "avatar" not in img_src:
            image_links.append(img_src)

# 创建保存图片的文件夹
if not os.path.exists("images"):
    os.makedirs("images")

# 下载图片并保存到文件夹
for i, image_link in enumerate(image_links):
    try:
        # 有些图片链接可能是相对路径，需要拼接完整URL
        if not image_link.startswith("http"):
            image_link = urljoin(url, image_link)
        response = requests.get(image_link, headers=headers)
        # 保存图片
        with open(f"images/image{i + 1}.jpg", "wb") as file:
            file.write(response.content)
        print(f"Downloaded image {i + 1}: {image_link}")
    except Exception as e:
        print(f"Failed to download image {i + 1}: {e}")
